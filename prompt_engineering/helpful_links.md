--Gemini Keys  
[Gemini Doc](https://ai.google.dev/gemini-api/docs/openai)  
[Gemini rate limit](https://ai.google.dev/gemini-api/docs/rate-limits)  
[ai studio](https://aistudio.google.com/app/apikey)  
[cloud console](https://console.cloud.google.com/apis/dashboard)  

--Groq links  
[grq api key ](https://console.groq.com/keys)  
[groq doc](https://console.groq.com/docs/text-chat)  
[groq rate limit](https://console.groq.com/settings/limits)

--Prompt Survey  
[Prompt report](https://arxiv.org/pdf/2406.06608)
[Prompt texonomy](https://mnehmos.github.io/Prompt-Engineering/reports/taxonomy-overview.html)
[openai prompt thumb rule](https://help.openai.com/en/articles/6654000-best-practices-for-prompt-engineering-with-the-openai-api)
[Openai Prompt](https://platform.openai.com/docs/guides/prompting)
https://learnprompting.org/docs/basics/generative_ai
https://www.promptingguide.ai/
https://learnprompting.org/docs/basics/prompt_structure

https://www.promptingguide.ai/guides/context-engineering-guide


https://www.phdata.io/blog/how-to-tune-llm-parameters-for-top-performance-understanding-temperature-top-k-and-top-p/
https://multimodalai.substack.com/p/understanding-llm-inference?utm_source=chatgpt.com
https://arxiv.org/pdf/2404.14294
https://deepsense.ai/blog/llm-inference-optimization-how-to-speed-up-cut-costs-and-scale-ai-models/?utm_source=chatgpt.com
https://www.aussieai.com/blog/llm-inference-optimization.htm?utm_source=chatgpt.com

For top p, k, and temp best 
https://www.carneiro.dev/blog/ai/llm-sampling-parameters?utm_source=chatgpt.com

[prompting](https://docs.promptlayer.com/introduction)

 



